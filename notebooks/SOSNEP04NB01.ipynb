{
    "metadata": {
        "kernelspec": {
            "name": "SQL",
            "display_name": "SQL",
            "language": "sql"
        },
        "language_info": {
            "name": "sql",
            "version": ""
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "SOSNEP03NB01\n",
                "\n",
                "<img src=\"https://raw.githubusercontent.com/microsoft/dataexposed/main/graphics/sosn-white-new-very-small.jpg\" alt=\"Logo\" height=\"150\">"
            ],
            "metadata": {
                "azdata_cell_guid": "5cd39845-9699-4a6b-895e-19a75e6f062d"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Regression Classification with R\n",
                "\n",
                "Using a built-in data set consisting of 81 observations of four variables (Age, Number, Kyphosis, Start) in children following corrective spinal surgery, this is an example of R with the glm algorithm to do a prediction of a possible medical condition. The variable Kyphosis reports the absence or presence of this deformity.\n",
                "\n",
                "[Docs Reference](https://docs.microsoft.com/en-us/machine-learning-server/r/how-to-revoscaler-logistic-regression)"
            ],
            "metadata": {
                "azdata_cell_guid": "e8fed3cb-77bf-4c53-b22c-05b43ec86af7"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "EXECUTE sp_execute_external_script @language = N'R'\r\n",
                "    , @script = N'\r\n",
                "library(rpart)\r\n",
                "dataresults <- rxLogit(Kyphosis ~ Age + Start + Number, data = kyphosis)\r\n",
                "print(dataresults)\r\n",
                "'"
            ],
            "metadata": {
                "azdata_cell_guid": "aca95bd7-8ac2-426d-8422-15d59b5506b2"
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "STDOUT message(s) from external script: \nRows Read: 81, Total Rows Processed: 81, Total Chunk Time: 0.003 seconds \n\nStarting values (iteration 1) time: 0.009 secs.\nRows Read: 81, Total Rows Processed: 81, Total Chunk Time: 0.003 seconds \n\nIteration 2 time: 0.009 secs.\nRows Read: 81, Total Rows Processed: 81, Total Chunk Time: 0.002 seconds \n\nIteration 3 time: 0.008 secs.\nRows Read: 81, Total Rows Processed: 81, Total Chunk Time: 0.002 seconds \n\nIteration 4 time: 0.007 secs.\nRows Read: 81, Total Rows Processed: 81, Total Chunk Time: 0.002 seconds \n\nIteration 5 time: 0.006 secs.\nRows Read: 81, Total Rows Processed: 81, Total Chunk Time: 0.002 seconds \n\nIteration 6 time: 0.007 secs.\n\nElapsed computation time: 0.048 secs.\nLogistic Regression Results for: Kyphosis ~ Age + Start + Number\nData: kyphosis\nDependent variable(s): Kyphosis\nTotal independent variables: 4 \nNumber of valid observations: 81\nNumber of missing observations: 0 \n \nCoefficients:\n               Kyphosis\n(Intercept) -2.03693354"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "STDOUT message(s) from external script: \nAge          0.01093048\nStart       -0.20651005\nNumber       0.41060119"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Total execution time: 00:00:01.679"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 12
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Anomaly detection using SVM in Python\n",
                "\n",
                "Using an example from the [SciKitLearn Python Package](https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html#sphx-glr-auto-examples-svm-plot-separating-hyperplane-py), this example shows how to detect an anomaly in data using a Support Vector Machine. \n",
                "\n",
                "Another example: [https://docs.microsoft.com/en-us/machine-learning-server/python-reference/microsoftml/rx-oneclass-svm](https://docs.microsoft.com/en-us/machine-learning-server/python-reference/microsoftml/rx-oneclass-svm)\n",
                "\n",
                "And another: [https://analyticsindiamag.com/understanding-the-basics-of-svm-with-example-and-python-implementation/](https://analyticsindiamag.com/understanding-the-basics-of-svm-with-example-and-python-implementation/)"
            ],
            "metadata": {
                "azdata_cell_guid": "c7c52460-6472-4a17-bd26-65d509f2f53c"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "EXECUTE sp_execute_external_script @language = N'Python'\r\n",
                "    , @script = N'\r\n",
                "\r\n",
                "import numpy as np\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "from sklearn import svm\r\n",
                "from sklearn.datasets import make_blobs\r\n",
                "\r\n",
                "\r\n",
                "# we create 40 separable points\r\n",
                "X, y = make_blobs(n_samples=40, centers=2, random_state=6)\r\n",
                "\r\n",
                "# fit the model, do not regularize for illustration purposes\r\n",
                "clf = svm.SVC(kernel=\"linear\", C=1000)\r\n",
                "clf.fit(X, y)\r\n",
                "\r\n",
                "plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\r\n",
                "\r\n",
                "# plot the decision function\r\n",
                "ax = plt.gca()\r\n",
                "xlim = ax.get_xlim()\r\n",
                "ylim = ax.get_ylim()\r\n",
                "\r\n",
                "# create grid to evaluate model\r\n",
                "xx = np.linspace(xlim[0], xlim[1], 30)\r\n",
                "yy = np.linspace(ylim[0], ylim[1], 30)\r\n",
                "YY, XX = np.meshgrid(yy, xx)\r\n",
                "xy = np.vstack([XX.ravel(), YY.ravel()]).T\r\n",
                "Z = clf.decision_function(xy).reshape(XX.shape)\r\n",
                "\r\n",
                "# plot decision boundary and margins\r\n",
                "ax.contour(XX, YY, Z, colors=\"k\", levels=[-1, 0, 1], alpha=0.5,\r\n",
                "           linestyles=[\"--\", \"-\", \"--\"])\r\n",
                "# plot support vectors\r\n",
                "ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,\r\n",
                "           linewidth=1, facecolors=\"none\", edgecolors=\"k\")\r\n",
                "\r\n",
                "plt.savefig(\"SOSONEP04PyPlot01.pdf\") \r\n",
                "'"
            ],
            "metadata": {
                "azdata_cell_guid": "5de3fe87-24f4-42cd-8a60-fafe9625003f"
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Commands completed successfully."
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Total execution time: 00:00:06.263"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 32
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Decision Trees in Python - Birth result predictions\n",
                "\n",
                "Using the `infert` built-in dataset, this example uses the Microsoft `rx_fast_trees` library, which is an implementation of FastRank. FastRank is an efficient implementation of the MART gradient boosting algorithm. Gradient boosting is a machine learning technique for regression problems. It builds each regression tree in a step-wise fashion, using a predefined loss function to measure the error for each step and corrects for it in the next. So this prediction model is actually an ensemble of weaker prediction models. In regression problems, boosting builds a series of such trees in a step-wise fashion and then selects the optimal tree using an arbitrary differentiable loss function.\n",
                "\n",
                "[Docs Reference](https://docs.microsoft.com/en-us/machine-learning-server/python-reference/microsoftml/rx-fast-trees)"
            ],
            "metadata": {
                "azdata_cell_guid": "87b30147-e20f-4b85-8064-8092fcd3850e"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "EXECUTE sp_execute_external_script @language = N'Python'\r\n",
                "    , @script = N'\r\n",
                "import numpy\r\n",
                "import pandas\r\n",
                "from microsoftml import rx_fast_trees, rx_predict\r\n",
                "from revoscalepy.etl.RxDataStep import rx_data_step\r\n",
                "from microsoftml.datasets.datasets import get_dataset\r\n",
                "\r\n",
                "infert = get_dataset(\"infert\")\r\n",
                "\r\n",
                "import sklearn\r\n",
                "if sklearn.__version__ < \"0.18\":\r\n",
                "    from sklearn.cross_validation import train_test_split\r\n",
                "else:\r\n",
                "    from sklearn.model_selection import train_test_split\r\n",
                "\r\n",
                "infertdf = infert.as_df()\r\n",
                "infertdf[\"isCase\"] = infertdf.case == 1\r\n",
                "data_train, data_test, y_train, y_test = train_test_split(infertdf, infertdf.isCase)\r\n",
                "\r\n",
                "trees_model = rx_fast_trees(\r\n",
                "    formula=\" isCase ~ age + parity + education + spontaneous + induced \",\r\n",
                "    data=data_train)\r\n",
                "    \r\n",
                "# RuntimeError: The type (RxTextData) for file is not supported.\r\n",
                "score_ds = rx_predict(trees_model, data=data_test,\r\n",
                "                     extra_vars_to_write=[\"isCase\", \"Score\"])\r\n",
                "                     \r\n",
                "# Print the first five rows\r\n",
                "print(rx_data_step(score_ds, number_rows_read=5))\r\n",
                "'"
            ],
            "metadata": {
                "azdata_cell_guid": "bf45d03e-2818-43b0-b203-f43c78d2ef93"
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "STDOUT message(s) from external script: \nWarning: numpy.int64 data type is not supported. Data is converted to float64.\nNot adding a normalizer.\nMaking per-feature arrays\nChanging data from row-wise to column-wise\nBeginning processing data.\nRows Read: 186, Read Time: 0.000200987, Transform Time: 4.05312e-06\nBeginning processing data.\nProcessed 186 instances\nBinning and forming Feature objects\nReserved memory for tree learner: 7176 bytes\nStarting to train ...\nNot training a calibrator because it is not needed.\nElapsed time: 00:00:01.3655709\nElapsed time: 00:00:00.2479184\nWarning: numpy.int64 data type is not supported. Data is converted to float64.\nBeginning processing data.\nRows Read: 62, Read Time: 0.000154972, Transform Time: 4.05312e-06\nBeginning processing data.\nElapsed time: 00:00:00.1365048\nFinished writing 62 rows.\nWriting completed.\nRows Read: 5, Total Rows Processed: 5, Total Chunk Time: 0.004 seconds \n   isCase  PredictedLabel      Score  Probability"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "STDOUT message(s) from external script: \n0    True           False  -9.047059     0.026114\n1   False           False  -6.661149     0.065103\n2   False           False -16.508970     0.001354\n3    True           False  -3.403884     0.203988\n4   False           False -13.369946     0.004735"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Total execution time: 00:00:07.194"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Naïve Bayes in Data Mining in R\r\n",
                "\r\n",
                "As an ongoing promotional strategy, the marketing department for the Adventure Works Cycle company has decided to target potential customers by mailing out fliers. To reduce costs, they want to send fliers only to those customers who are likely to respond. The company stores information in a database about demographics and response to a previous mailing. They want to use this data to see how demographics such as age and location can help predict response to a promotion, by comparing potential customers to customers who have similar characteristics and who have purchased from the company in the past. Specifically, they want to see the differences between those customers who bought a bicycle and those customers who did not.\r\n",
                "\r\n",
                "[Docs Reference](https://docs.microsoft.com/en-us/analysis-services/data-mining/microsoft-naive-bayes-algorithm?view=asallproducts-allversions)"
            ],
            "metadata": {
                "azdata_cell_guid": "582b1ac3-a255-4c85-aa70-8be5d389a3f7"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "EXECUTE sp_execute_external_script @language = N'R'\r\n",
                "    , @script = N'\r\n",
                "# Required Packages\r\n",
                "# install.packages(\"e1071\")\r\n",
                "# install.packages(\"caTools\")\r\n",
                "# install.packages(\"caret\")\r\n",
                "  \r\n",
                "# Loading package\r\n",
                "library(e1071)\r\n",
                "library(caTools)\r\n",
                "library(caret)\r\n",
                "  \r\n",
                "# Split data into test/train\r\n",
                "# and test data\r\n",
                "split <- sample.split(iris, SplitRatio = 0.7)\r\n",
                "train_cl <- subset(iris, split == \"TRUE\")\r\n",
                "test_cl <- subset(iris, split == \"FALSE\")\r\n",
                "  \r\n",
                "# Feature Engineering\r\n",
                "train_scale <- scale(train_cl[, 1:4])\r\n",
                "test_scale <- scale(test_cl[, 1:4])\r\n",
                "  \r\n",
                "# Create Naive Bayes Model \r\n",
                "# to training dataset\r\n",
                "set.seed(120)  # Setting Seed\r\n",
                "classifier_cl <- naiveBayes(Species ~ ., data = train_cl)\r\n",
                "classifier_cl\r\n",
                "  \r\n",
                "# Predict using test data\r\n",
                "y_pred <- predict(classifier_cl, newdata = test_cl)\r\n",
                "  \r\n",
                "# Create a Confusion Matrix\r\n",
                "cm <- table(test_cl$Species, y_pred)\r\n",
                "cm\r\n",
                "  \r\n",
                "# Evauate the model\r\n",
                "confusionMatrix(cm)\r\n",
                "'"
            ],
            "metadata": {
                "azdata_cell_guid": "1607ed8a-9797-403a-a07c-72eb30ec7c91"
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "## Neural Networks preview\n",
                "\n",
                "https://docs.microsoft.com/en-us/archive/blogs/mlserver/galaxy-classification-with-neural-networks-a-data-science-workflow"
            ],
            "metadata": {
                "azdata_cell_guid": "a3d214f3-53f7-45f4-a477-095369645cf3"
            }
        }
    ]
}